library(tidyverse)
library(vegbankr)
library(remotes)
library(httr)
library(cli)
library(glue)
source('R/build_loader_table.R')


load_stratacover_files <- function(in_dir, out_dir){
  # loading CA lookup table
  sub_folders <- dir(in_dir, full.names = TRUE) %>%
    grep(pattern = "VegBankProject", value = TRUE)
  
  plant_files <- dir(sub_folders, full.names = TRUE) %>% 
    grep(pattern = 'RAPlants.csv', value = TRUE)
  
  if (length(plant_files) == 0) {
    cli_abort("No RAPlants.csv files found under {in_dir}.")
  }
  
  plants_df_list <- lapply(plant_files, 
                           read_csv,
                           progress = FALSE,
                           show_col_types = FALSE,
                           guess_max = 20000)
  plants <- do.call(bind_rows, plants_df_list)
  
  if (nrow(plants) == 0) {
    cli_abort("RAPlants.csv files were found but produced 0 rows after reading.")
  }
  
  # generate a lookup table to link observations to contributors
  ctib_path <- file.path(out_dir, "contributorLT.csv")
  
  if (!file.exists(ctib_path)){
    cli::cli_abort("Contributor loader table not found. Check {out_dir} for the presence of contributorLT.csv. This file is generated by `R/party_contributor_loader.R`")
  }
  contrib <- read_csv(ctib_path, show_col_types = FALSE, progress = FALSE) %>% 
    rename(proj_code = record_identifier)
  
  plots_path <- file.path(out_dir, "plotsLT.csv")
  if (!file.exists(plots_path)){
    cli::cli_abort("Plots loader table not found. Check {out_dir} for the presence of plotsLT.csv. This file is generated by `R/plots_loader.R`")
  }
  plots <- read_csv(plots_path, show_col_types = FALSE, progress = FALSE) %>% 
    rename(proj_code = user_pj_code, SurveyID = user_ob_code) %>% 
    select(SurveyID, proj_code) %>% 
    distinct()
  
  ret <- list("plants" = plants, "contrib" = contrib, "plots" = plots)
  return(ret)
}

create_person_lookup <- function(plots, contrib){
  # organized into most to least likely to be involved in classification
  #TODO: ask CDFW about this, backstop could also be to put an org or generic entry in if no relevant party is found
  roles <- tibble::tribble(
    ~ar_code, ~role_name,
    "ar.55", "Taxonomist",
    "ar.34", "Classifier",
    "ar.18", "PI",
    "ar.38", "Co-PI",
    "ar.16", "Author",
    "ar.51", "Publication author",
    "ar.36", "Plot author",
    "ar.53", "Research advisor",
    "ar.19", "Data Manager",
    "ar.50", "Plot contributor",
    "ar.40", "Consultant",
    "ar.17", "Contact",
    "ar.54", "System manager",
    "ar.56", "Data aggregator",
    "ar.39", "Computer (automated)",
    "ar.43", "Field assistant",
    "ar.44", "Guide",
    "ar.48", "Passive observer",
    "ar.45", "Land owner",
    "ar.46", "Not specified",
    "ar.47", "Not specified/Unknown"
  )
  contrib$vb_ar_code <- factor(contrib$vb_ar_code, levels = roles$ar_code)
  
  
  obs_proj_lookup <- full_join(plots, contrib, relationship = "many-to-many", by = "proj_code") %>% 
    group_by(SurveyID) %>%
    slice_min(vb_ar_code, n = 1, with_ties = FALSE) %>% 
    select(SurveyID, user_py_code)
  
  return(obs_proj_lookup)
}

load_usda_plants <- function(){
  # TODO: figure out if this is necessary
  csv_path <- file.path(in_dir, "lookup-tables/USDA_PLANTS.csv")
  plants_lookup <- read_csv(csv_path, show_col_types = FALSE) # ignore parsing issue
  if (!file.exists("data/plantlist.txt")){
    url <- "https://plants.sc.egov.usda.gov/DocumentLibrary/Txt/plantlst.txt"
    download.file(url, destfile = "data/plantlist.txt", mode = "wb")
  }
  plant_list <- read.delim("data/plantlist.txt", sep = ",", header = TRUE)
  # end TODO
}

load_vb_pc <- function(base_url, renew_cache = FALSE){
  
  cache_dir  <- rappdirs::user_cache_dir("vegbank")
  cache_file <- file.path(cache_dir, "plant_concept_all.csv")
  
  if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)
  
  if (!file.exists(cache_file) | renew_cache) {

    vb_set_base_url(base_url)   
    
    page_init <- 5000 # shrink this if there is an error
    page_min <- 500 # don't go smaller than this
    max_pages <- 500 # hard stop
    sleep_sec <- 0.05 # brief pause to avoid error
    checkpoint <- "pc_all_checkpoint.rds" # just in case something fails
    save_every <- 10
    
    out <- list()
    seen_codes <- character(0)
    limit <- page_init
    
    for (i in seq_len(max_pages)) {
      offset <- (i - 1L) * limit
      message(sprintf("Page %d | limit=%d | offset=%d", i, limit, offset))
      
      #  try once; on failure (e.g., 504), halve the limit and retry
      chunk <- tryCatch(
        vb_get_plant_concepts(limit = limit, offset = offset),
        error = function(e) {
          message("  Request failed: ", conditionMessage(e))
          limit <<- max(page_min, floor(limit/2))
          message("  Reducing limit and retrying with limit=", limit)
          tryCatch(vb_get_plant_concepts(limit = limit, offset = offset),
                   error = function(e2) { message("  Retry failed."); NULL })
        }
      )
      if (is.null(chunk) || !nrow(chunk)) { message("  No rows returned; stopping."); break }
      
      # Convert plant_code to character to avoid type conflicts
      if ("plant_code" %in% names(chunk)) {
        chunk$plant_code <- as.character(chunk$plant_code)
      }
      
      if ("pc_code" %in% names(chunk)) {
        new <- !chunk$pc_code %in% seen_codes
        if (!any(new)) { message("  All rows seen already; stopping."); break }
        seen_codes <- c(seen_codes, chunk$pc_code[new])
        chunk <- chunk[new, , drop = FALSE]
      }
      
      out[[length(out) + 1L]] <- chunk
      total <- sum(vapply(out, nrow, integer(1)))
      message(sprintf("  +%d new rows (total: %d)", nrow(chunk), total))
      
      if (nrow(chunk) < limit) { message("  Short page; done."); break }
      
      if (save_every > 0 && (i %% save_every == 0)) {
        
        tryCatch(
          {
            tmp <- dplyr::bind_rows(out) %>% distinct()
          },
          error = function(e) {
            tmp <<- bind_rows(lapply(out, function(df) mutate(df, across(everything(), as.character))))
          }
        )
        saveRDS(tmp, checkpoint)
        message(sprintf("  Saved checkpoint (%d rows) -> %s", nrow(tmp), checkpoint))
      }
      
      if (sleep_sec > 0) Sys.sleep(sleep_sec)
    }
    tryCatch(
      {
        pc_all <- dplyr::bind_rows(out) %>% distinct()
      },
      error = function(e) {
        pc_all <<- bind_rows(lapply(out, function(df) mutate(df, across(everything(), as.character))))
      }
    )
    message(sprintf("Finished. Total plant concepts: %d", nrow(pc_all)))
    
    write_csv(pc_all, cache_file)
  } else {
    pc_all <- read.csv(cache_file)
  }
  return(pc_all)
}

stratacover_taxon_loader <- function(in_dir, out_dir){

  l <- load_stratacover_files(in_dir, out_dir)
  list2env(l, envir = environment())
  people <- create_person_lookup(plots, contrib)
  
  pc_all <- load_vb_pc("https://api-dev.vegbank.org", FALSE)

  # try to match most recent USDA codes, moving down through older lists if no matches are found
  
  pc_usda <- pc_all %>%
    filter(grepl("USDA Plants", concept_rf_label))
  
  pc_usda$concept_rf_label <- factor(pc_usda$concept_rf_label, levels = sort(unique(pc_usda$concept_rf_label)))
  
  pc_lookup_no_repeats <- pc_usda %>% 
    group_by(plant_code) %>% 
    slice_max(concept_rf_label, n = 1, with_ties = FALSE) %>% 
    select(pc_code, plant_code, plant_name, concept_rf_label) %>% 
    ungroup()
  
  # for both species name and plant code/symbol, take the most recent one first (SpeciesName, CurrPlantsSymbol). if that
  # field is NA, take the other (Species_name, CodeSpecies)
  n0 <- nrow(plants)
  
  plants_join <- plants %>% 
    mutate(strata_id = paste(SurveyID, Stratum, sep = "_")) %>% 
    mutate(usda_norm = if_else(is.na(CurrPlantsSymbol), CodeSpecies, CurrPlantsSymbol)) %>% 
    left_join(pc_lookup_no_repeats, by = c("usda_norm" = "plant_code"))
  
  if (nrow(plants_join) != n0) {
    cli_alert_warning("Row count changed after joining plant concepts: {n0} -> {nrow(plants_join)}. This indicates duplicate plant_code values in the lookup.")
  }
  
  plants_join <- plants_join %>%
    left_join(people, by = join_by(SurveyID)) %>% 
    mutate(user_to_code = paste0("CDFW_plant_", row_number())) %>% 
    mutate(species_norm = if_else(is.na(SpeciesName), Species_name, SpeciesName))
  
  if (nrow(plants_join) != n1) {
    cli_alert_warning("Row count changed after joining people: {n1} -> {nrow(plants_join)}. This indicates duplicate SurveyID values in the people lookup.")
  }

  if (length(which(is.na(plants_join$user_py_code))) > 0){
    cli::cli_alert_warning("{length(which(is.na(plants_join$user_py_code)))} rows have NA values for `user_py_code`. A person and role are required for the taxon interpretations loader table.")
  }
  
  if (any(is.na(plants_join$pc_code))) {
    cli_alert_warning("{sum(is.na(plants_join$pc_code))} rows have NA `pc_code` (required for ingest).")
    bad <- plants_join %>%
      filter(is.na(pc_code), !is.na(usda_norm), str_squish(usda_norm) != "") %>%
      distinct(usda_norm) %>%
      pull(usda_norm)
    cli_text("Sample unmapped USDA codes:")
    cli_ul(head(bad, 15))
  }
  
  #TODO: figure out if stratum is even required here?
  # assign a stratum method for each project, join back to plot obs/strata cover
  # each row in this table needs to join to strataDefinitionsLT
  vb_strat <- vb_get_stratum_methods(limit = 5000)
  
  # loader tables
  strata_cover_template_fields <- build_loader_table(
    sheet_url = "https://docs.google.com/spreadsheets/d/1ORubguw1WDkTkfiuVp2p59-eX0eA8qMQUEOfz1TWfH0/edit?gid=2109807393#gid=2109807393",
    sheet = "StrataCoverData",
    source_df = plants
  )
  
  taxon_template_fields <- build_loader_table(
    sheet_url = "https://docs.google.com/spreadsheets/d/1ORubguw1WDkTkfiuVp2p59-eX0eA8qMQUEOfz1TWfH0/edit?gid=2109807393#gid=2109807393",
    sheet = "TaxonInterpretations",
    source_df = plants
  )
  
  strata_cover_LT <- strata_cover_template_fields$template
  taxon_LT <- taxon_template_fields$template
  
  #strata_cover_LT$user_sr_code <- plants_join$Stratum
  strata_cover_LT$user_to_code <- plants_join$user_to_code
  strata_cover_LT$user_ob_code <- plants_join$SurveyID
  strata_cover_LT$user_sr_code <- plants_join$strata_id
  strata_cover_LT$author_plant_name <- plants_join$species_norm
  strata_cover_LT$cover <- plants_join$Species_cover
  
  taxon_LT$user_to_code <- plants_join$user_to_code
  taxon_LT$user_py_code <- plants_join$user_py_code
  taxon_LT$vb_pc_code <- plants_join$pc_code
  taxon_LT$original_interpretation <- TRUE
  taxon_LT$current_interpretation <- TRUE
  
  out_path_strata <- file.path(out_dir, "strataCoverLT.csv")
  out_path_tax <- file.path(out_dir, 'taxonInterpretationsLT.csv')
  cli::cli_alert_success("Writing two output files to:")
  cli::cli_ul(c(out_path_strata, out_path_tax))
  
  write.csv(strata_cover_LT, out_path_strata, row.names = F)
  write.csv(taxon_LT, out_path_tax, row.names = F)
    
}

